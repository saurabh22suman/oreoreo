{
  "profile": {
    "name": "Saurabh Suman",
    "title": "Senior Data Engineer",
    "avatar": "https://api.dicebear.com/7.x/avataaars/svg?seed=Saurabh",
    "location": "Pune, India",
    "email": "soloengine007@gmail.com",
    "summary": "Senior Data Engineer with 7+ years of experience specializing in Databricks, Azure, Fabric, AWS and Delta Lake with strong skills in Python, PySpark, SQL, and medallion architecture. Experienced in building scalable pipelines, optimizing performance, and delivering analytics-ready datasets.",
    "photo": "/uploads/profile-photo.jpg",
    "resume": "/uploads/resume.pdf"
  },
  "socials": [
    {
      "platform": "GitHub",
      "url": "https://github.com/saurabh22suman",
      "icon": "github"
    },
    {
      "platform": "Portfolio",
      "url": "https://me.soloengine.in/",
      "icon": "globe"
    },
    {
      "platform": "Medium",
      "url": "https://medium.com/@saurabh22suman",
      "icon": "medium"
    },
    {
      "platform": "Email",
      "url": "mailto:soloengine007@gmail.com",
      "icon": "email"
    }
  ],
  "skills": [
    {
      "category": "Cloud Platforms",
      "items": [
        "Azure ADF",
        "Databricks",
        "Synapse",
        "Microsoft Fabric",
        "AWS Glue",
        "S3",
        "Bedrock",
        "Aurora",
        "EC2",
        "SageMaker"
      ]
    },
    {
      "category": "Data Engineering",
      "items": [
        "PySpark",
        "Delta Lake",
        "Unity Catalog",
        "Medallion Architecture",
        "ETL/ELT",
        "Data Modelling"
      ]
    },
    {
      "category": "Programming",
      "items": [
        "Python",
        "SQL",
        "PySpark",
        "Pandas"
      ]
    },
    {
      "category": "Orchestration & DevOps",
      "items": [
        "Azure DevOps",
        "Git",
        "CI/CD Pipelines",
        "Docker"
      ]
    },
    {
      "category": "Analytics & BI",
      "items": [
        "Power BI",
        "KQL",
        "Excel"
      ]
    },
    {
      "category": "AI/ML",
      "items": [
        "LLMs (Amazon Bedrock)",
        "GPT",
        "RAG Pipelines",
        "Optimization (PuLP)"
      ]
    }
  ],
  "projects": [
    {
      "title": "Multi-Agent LLM Query System",
      "description": "Designed a Multi-Agent LLM Query System using Amazon Bedrock to enable natural language querying on Amazon Aurora. Built a scalable backend hosted on EC2 with async inference.",
      "technologies": [
        "Amazon Bedrock",
        "Aurora",
        "S3",
        "EC2",
        "SageMaker",
        "RAG"
      ],
      "url": "",
      "github": ""
    },
    {
      "title": "Enterprise IoT Data Pipeline",
      "description": "Enhanced enterprise-scale ingestion pipelines processing IoT sensor streams, machine logs, and application logs into a medallion (bronze–silver–gold) architecture using Synapse and Databricks.",
      "technologies": [
        "Azure Synapse",
        "Databricks",
        "Event Streams",
        "ADLS",
        "Power BI",
        "PySpark"
      ],
      "url": "",
      "github": ""
    },
    {
      "title": "Microsoft Fabric Migration",
      "description": "Led migration of legacy ADF + Synapse workloads to Microsoft Fabric. Implemented Fabric Lakehouse and Warehouse models with HIPAA-compliant data governance.",
      "technologies": [
        "Microsoft Fabric",
        "Azure Data Factory",
        "Synapse",
        "Databricks",
        "ADLS Gen2",
        "Power BI"
      ],
      "url": "",
      "github": ""
    },
    {
      "title": "Optimization Engine Pipelines",
      "description": "Built Optimization Engine Pipelines ingesting multi-source data using ADF and Databricks. Developed serverless APIs with Azure Functions to return optimized JSON responses in real time.",
      "technologies": [
        "Azure ADF",
        "Databricks",
        "Azure Functions",
        "Python",
        "Pandas",
        "PuLP"
      ],
      "url": "",
      "github": ""
    },
    {
      "title": "Azure Subscription Cost Analytics",
      "description": "Developed Azure Subscription Cost Analytics using ADF pipelines with in-line KQL transformations. Loaded curated datasets into SQL Server for Power BI cost dashboards.",
      "technologies": [
        "Azure ADF",
        "Log Analytics",
        "KQL",
        "SQL Server",
        "Power BI"
      ],
      "url": "",
      "github": ""
    }
  ],
  "experience": [
    {
      "company": "Fujitsu India Pvt. Ltd.",
      "role": "Application Developer",
      "period": "Jan 2025 - Present",
      "highlights": [
        "Enhanced enterprise-scale ingestion pipelines processing IoT sensor streams, machine logs, and application logs into medallion architecture",
        "Built optimized bronze, silver, and gold layers using Synapse and Databricks; developed curated fact and dimension models powering Power BI analytics",
        "Improved pipeline reliability and observability through structured logging, automated retries, and event-driven alerting",
        "Designed a Multi-Agent LLM Query System using Amazon Bedrock for natural language querying on Amazon Aurora",
        "Built scalable backend hosted on EC2 with async inference; optimized model evaluation using Amazon SageMaker"
      ]
    },
    {
      "company": "Citiustech Healthcare Technology",
      "role": "Technical Lead - I",
      "period": "Sept 2024 - Jan 2025",
      "highlights": [
        "Led a team of 4 engineers to migrate legacy ADF + Synapse workloads to Microsoft Fabric",
        "Rewrote PySpark logic from Databricks to Fabric Spark; implemented Fabric Lakehouse and Warehouse models",
        "Designed HIPAA-compliant data governance: IAM roles, RBAC, network isolation, and workspace-level security",
        "Performed code reviews, estimations, sprint planning, and mentored junior engineers",
        "Delivered migration with zero downtime and improved query performance across Power BI datasets"
      ]
    },
    {
      "company": "Tiger Analytics",
      "role": "Data Scientist",
      "period": "June 2022 - Sept 2024",
      "highlights": [
        "Built Optimization Engine Pipelines ingesting multi-source data using ADF and Databricks",
        "Implemented preprocessing, postprocessing, and optimization workflows using PySpark, Pandas, and PuLP",
        "Developed serverless APIs with Azure Functions (HTTP trigger) to return optimized JSON responses in real time",
        "Built End-to-End Reporting Pipelines from ingestion to curated outputs and automated report dissemination",
        "Exported curated data as Excel and automated uploads to SharePoint; triggered Power BI dataset refresh"
      ]
    },
    {
      "company": "Infosys",
      "role": "Specialist Programmer",
      "period": "June 2018 - June 2022",
      "highlights": [
        "Developed Azure Subscription Cost Analytics using ADF pipelines with in-line KQL transformations",
        "Processed Log Analytics data using Kusto Query Language; reduced unnecessary data movement",
        "Built Internet Banking Backend Services using Java Spring Boot for OD, deposits, cheques, and scheduled jobs",
        "Redesigned UI screens for OD and account info using Angular 7, TypeScript, and Bootstrap"
      ]
    }
  ],
  "certifications": [
    {
      "name": "Certified Data Engineer Associate",
      "issuer": "Databricks",
      "year": "2025",
      "url": "https://credentials.databricks.com/"
    },
    {
      "name": "Fabric Data Engineer Associate",
      "issuer": "Microsoft",
      "year": "2025",
      "url": "https://learn.microsoft.com/en-us/credentials/"
    },
    {
      "name": "Azure Data Fundamentals",
      "issuer": "Microsoft",
      "year": "2025",
      "url": "https://learn.microsoft.com/en-us/credentials/"
    }
  ],
  "education": [
    {
      "institution": "Jabalpur Engineering College",
      "degree": "Bachelor of Engineering in Information Technology",
      "year": "2014 - 2018"
    }
  ],
  "interests": [
    "Computing",
    "Traveling",
    "Lawn Tennis",
    "Table Tennis",
    "3D Printing",
    "Technology",
    "Problem solving"
  ]
}